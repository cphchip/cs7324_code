{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='https://fonts.googleapis.com/css?family=Passion+One' rel='stylesheet' type='text/css'><style>div.attn { font-family: 'Helvetica Neue'; font-size: 30px; line-height: 40px; color: #FFFFFF; text-align: center; margin: 30px 0; border-width: 10px 0; border-style: solid; border-color: #5AAAAA; padding: 30px 0; background-color: #DDDDFF; }hr { border: 0; background-color: #ffffff; border-top: 1px solid black; }hr.major { border-top: 10px solid #5AAA5A; }hr.minor { border: none; background-color: #ffffff; border-top: 5px dotted #CC3333; }div.bubble { width: 65%; padding: 20px; background: #DDDDDD; border-radius: 15px; margin: 0 auto; font-style: italic; color: #f00; }em { color: #AAA; }div.c1{visibility:hidden;margin:0;height:0;}div.note{color:red;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Ebnable HTML/CSS \n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<link href='https://fonts.googleapis.com/css?family=Passion+One' rel='stylesheet' type='text/css'><style>div.attn { font-family: 'Helvetica Neue'; font-size: 30px; line-height: 40px; color: #FFFFFF; text-align: center; margin: 30px 0; border-width: 10px 0; border-style: solid; border-color: #5AAAAA; padding: 30px 0; background-color: #DDDDFF; }hr { border: 0; background-color: #ffffff; border-top: 1px solid black; }hr.major { border-top: 10px solid #5AAA5A; }hr.minor { border: none; background-color: #ffffff; border-top: 5px dotted #CC3333; }div.bubble { width: 65%; padding: 20px; background: #DDDDDD; border-radius: 15px; margin: 0 auto; font-style: italic; color: #f00; }em { color: #AAA; }div.c1{visibility:hidden;margin:0;height:0;}div.note{color:red;}</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Enter Team Member Names here (*double click to edit*):\n",
    "\n",
    "- Name 1: Chip Henderson\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Assignment Two\n",
    "In the following assignment you will be asked to fill in python code and derivations for a number of different problems. Please read all instructions carefully and turn in the rendered notebook (or HTML of the rendered notebook)  before the end of class (or right after class). The initial portion of this notebook is given before class and the remainder is given during class. Please answer the initial questions before class, to the best of your ability. Once class has started you may rework your answers as a team for the initial part of the assignment. \n",
    "\n",
    "<a id=\"top\"></a>\n",
    "## Contents\n",
    "* <a href=\"#Loading\">Loading the Data</a>\n",
    "* <a href=\"#ff\">Defining a Feedforward Network in Python</a>\n",
    "* Available during in class assignment:\n",
    "* <a href=\"#bp\">Back Propagation in Python</a>\n",
    "* <a href=\"#vis\">Visualizing Back Propagation</a>\n",
    "________________________________________________________________________________________________________\n",
    "\n",
    "<a id=\"Loading\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "## Loading the Data\n",
    "Please run the following code to read in the \"digits\" dataset from sklearn's data loading module. This data contains hand written digits for the characters 0-9.\n",
    "\n",
    "This will load the data into the variable `ds`. `ds` is a `bunch` object with fields like `ds.data` and `ds.target`. The field `ds.data` is a numpy matrix of the continuous features in the dataset. **The object is not a pandas dataframe. It is a numpy matrix.** Each row is a set of observed instances, each column is a different feature. It also has a field called `ds.target` that is an integer value we are trying to predict (i.e., a specific integer represents a specific person). Each entry in `ds.target` is a label for each row of the `ds.data` matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "-0.5 0.5\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# lets load up the handwritten digit dataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "ds = load_digits()\n",
    "X = ds.data/16.0-0.5\n",
    "y = ds.target\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.min(X),np.max(X))\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape and print a few of the images in the digits dataset\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True,)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[i].reshape(8, 8)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "**Question 1:** For the digits dataset, what does each column in $\\mathbf{X}$ represent? What does each row in $\\mathbf{X}$ represent? What does each value in $\\mathbf{X}$ represent? What does each unique value of the target, $y$ represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -  Each column represents a pixel and its location\n",
    " -  Each row represents an entire image of pixels\n",
    " -  Each value is a value 0 to 1 representing the grayscale value\n",
    " -  Each unique value of the target equals the corresponding number value, class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "**Question 2:** For the digits dataset, we want to train a neural network with one hidden layer. The hidden layer will have 30 neurons. What will be the size of the matrices in each layer? That is, what is the size of $\\mathbf{W}^{(1)}$ and what is the size of $\\mathbf{W}^{(2)}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -  W1.size() = (64,30)\n",
    " -  W2.size() = (30,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ff\"></a>\n",
    "<a href=\"#top\">Back to Top</a>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/eclarson/MachineLearningNotebooks/master/PDF_Slides/MultiLayerNetwork.png\" width=\"500\">\n",
    "\n",
    "\n",
    "# Defining a Feedforward Network\n",
    "\n",
    "Below we will setup the functions for use in a feedforward neural network **with two layers**. Take a quick look at the functions defined. There are a number of convenience functions including:\n",
    "- a function for the sigmoid calculation\n",
    "- a function to one hot encode the output\n",
    "- a function to add ones (for intercept/bias) terms on the row or column\n",
    "- an initialization function for initializing the weights\n",
    "\n",
    "A few functions are not yet implemented including:\n",
    "- a `fit` function\n",
    "- a `get_gradient` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X.T, how='row')\n",
    "        Z1 = W1 @ A1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        \n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Recall from the videos that all instances in $\\mathbf{X}$ can be fed into the network with a single matrix multiplication operation for each intermediate vector, $a^{(l)}$ and $z^{(l)}$. When we feed all the instances, $\\mathbf{X}$, the intermediate vectors, $a^{(l)}$ and $z^{(l)}$ get stacked together to form matrices, $\\mathbf{A}^{(l)}$ and $\\mathbf{Z}^{(l)}$. This is already done for you in the `_feedforward` function defined above.\n",
    "\n",
    "**Question 3:**\n",
    "For the digits dataset we are using and a network with 30 neurons in the hidden layer, what are the sizes of:\n",
    "- **Part A**: the intermediate vectors, $a^{(1)}$ and $a^{(2)}$\n",
    "- **Part B**: the intermediate vectors, $z^{(1)}$ and $z^{(2)}$\n",
    "- **Part C**: the intermediate matrices, $\\mathbf{A}^{(1)}$ and $\\mathbf{A}^{(2)}$\n",
    "- **Part D**: the intermediate matrices, $\\mathbf{Z}^{(1)}$ and $\\mathbf{Z}^{(2)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Enter you answer here (double click)*\n",
    "\n",
    "\n",
    "A. \n",
    "\n",
    "\n",
    "B.  \n",
    "\n",
    "\n",
    "C. \n",
    "\n",
    "\n",
    "D.  \n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
